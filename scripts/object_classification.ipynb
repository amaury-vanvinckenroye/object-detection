{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#mount_path = \"/content/drive\"\n",
    "#drive.mount(mount_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.facecolor\"] = \"w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the parent `src` folder accessible\n",
    "import os\n",
    "import sys\n",
    "p = os.path.abspath('..')\n",
    "sys.path.insert(1, p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.util.lr_scheduler import LRFinder, OneCycleScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data = Path(\"../data/VOC2012\")\n",
    "\n",
    "#root_drive = Path(mount_path) / \"My Drive\"\n",
    "#root_data = root_drive / \"object-detection/data/VOC2012\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Val\n",
    "main_path = root_data / \"ImageSets/Main\"\n",
    "\n",
    "def get_dataset_ids(split):\n",
    "  with open(main_path / f\"{split}.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "  return pd.DataFrame(\n",
    "    np.array(lines).T,\n",
    "    columns=(\"imageName\",)\n",
    "  )\n",
    "\n",
    "df_train = get_dataset_ids(\"train\")\n",
    "print(f\"len train: {len(df_train)}\")\n",
    "\n",
    "df_val = get_dataset_ids(\"val\")\n",
    "print(f\"len val: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect labels\n",
    "labels_train = []\n",
    "labels_val = []\n",
    "\n",
    "for filename in main_path.glob(\"*.txt\"):\n",
    "  parts = filename.stem.split(\"_\")\n",
    "  # ignore train.txt and val.txt\n",
    "  if len(parts) != 2: \n",
    "    continue\n",
    "\n",
    "  label, split = parts[0], parts[1]\n",
    "  if split == \"train\":\n",
    "    labels_train.append(label)\n",
    "  elif split == \"val\":\n",
    "    labels_val.append(label)\n",
    "  else:\n",
    "    # trainval\n",
    "    continue\n",
    "\n",
    "assert sorted(labels_train) == sorted(labels_val)\n",
    "\n",
    "# build label map\n",
    "label_map = {label: i for i, label in enumerate(sorted(labels_train))}\n",
    "label_map_inverse = {i: label for label, i in label_map.items()}\n",
    "n_outputs = len(label_map)\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build y_train & y_val\n",
    "include_difficult = True\n",
    "\n",
    "def build_y_dict(df, split):\n",
    "    \"\"\"Builds a dictionary with the image name as keys and the one-hot representation of labels as values\n",
    "    TODO add mask for difficult cases\n",
    "    \"\"\"\n",
    "    y_dict = {}\n",
    "    # initialize all keys of the dict\n",
    "    for row in df.itertuples():\n",
    "        y_dict[row.imageName] = np.zeros(len(label_map))\n",
    "\n",
    "    # loop through every label txt file\n",
    "    for label, idx in label_map.items():\n",
    "        with open(main_path / f\"{label}_{split}.txt\") as file:\n",
    "            lines = file.readlines()\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            parts = line.split(\" \")\n",
    "            image_name, ground_truth = parts[0], parts[-1]\n",
    "            if ground_truth == \"1\":\n",
    "                y_dict[image_name][idx] = 1\n",
    "            elif ground_truth == \"0\" and include_difficult:\n",
    "                y_dict[image_name][idx] = 1\n",
    "\n",
    "    return y_dict\n",
    "\n",
    "y_train = build_y_dict(df_train, \"train\")\n",
    "y_val = build_y_dict(df_val, \"val\")\n",
    "\n",
    "n_train, n_val = len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of labels\n",
    "def plot_distribution(y_dict):\n",
    "    summed_classes = np.zeros(len(label_map))\n",
    "    for y in y_dict.values():\n",
    "        summed_classes += y\n",
    "\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(list(label_map.values()), summed_classes)\n",
    "    ax.set_xticks(list(label_map.values()))\n",
    "    ax.set_xticklabels(list(label_map.keys()), rotation=60)\n",
    "    plt.show()\n",
    "\n",
    "plot_distribution(y_train)\n",
    "plot_distribution(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tf datasets\n",
    "jpeg_path = root_data / \"JPEGImages\"\n",
    "\n",
    "def buid_tf_datasets(y_dict):\n",
    "    jpeg_list = [str((jpeg_path / f\"{image_name}.jpg\").resolve()) for image_name in y_dict.keys()]\n",
    "    labels = [val for val in y_dict.values()]\n",
    "    return tf.data.Dataset.from_tensor_slices((jpeg_list, labels))\n",
    "\n",
    "ds_train = buid_tf_datasets(y_train)\n",
    "ds_val = buid_tf_datasets(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "# This has to be done in the tf.Data pipeline otherwise you can't batch data with variable input shapes\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "def rescale(image):\n",
    "    return tf.math.divide(image, 255)\n",
    "\n",
    "def resize(image):\n",
    "    # tf.image.resize raises an error about images having no shape when `from_generator` is used\n",
    "    #return tf.image.resize_with_pad(image, INPUT_SIZE[0], INPUT_SIZE[1], method=tf.image.ResizeMethod.BILINEAR, antialias=True)\n",
    "    return tf.image.resize(image, (INPUT_SIZE[0], INPUT_SIZE[1]), method=tf.image.ResizeMethod.BILINEAR, antialias=True)\n",
    "\n",
    "def clip_values(image):\n",
    "    return tf.clip_by_value(image, 0, 1)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = clip_values(resize(rescale(image)))\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(image_path, labels):\n",
    "    img_content = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(img_content)\n",
    "    return (preprocess_image(image), labels)\n",
    "\n",
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    ds_val\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds_train.as_numpy_iterator():\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.imshow(x[0])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 256\n",
    "\n",
    "ds_train = (\n",
    "    ds_train\n",
    "    .cache()\n",
    "    .shuffle(n_train)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    ds_val\n",
    "    .batch(1)\n",
    "    .cache()  # caching is done after batching because batches can be the same between epochs\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A simple sequential CNN model\n",
    "def simple_model():\n",
    "    inputs = tf.keras.Input(shape=(INPUT_SIZE[0], INPUT_SIZE[1], 3))\n",
    "    x = tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Conv2D(32, 5, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.MaxPooling2D(3, 1)(x)\n",
    "    x = tf.keras.layers.Conv2D(64, 9, padding=\"same\", activation=\"relu\")(inputs)\n",
    "    x = tf.keras.layers.Conv2D(128, 17, padding=\"same\", activation=\"relu\")(x)\n",
    "    x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "    outputs = tf.keras.layers.Dense(n_outputs)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"object-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A shorter version of Inception (~30% accuracy)\n",
    "def short_inception_model():\n",
    "\n",
    "  def conv2d_bn(x, filters, width, height, padding=\"same\", strides=(1, 1)):\n",
    "    x = tf.keras.layers.Conv2D(filters, (width, height), strides=strides, padding=padding, use_bias=False)(x)\n",
    "    x = tf.keras.layers.BatchNormalization(scale=False)(x)\n",
    "    x = tf.keras.layers.Activation('relu')(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def input_block(inputs):\n",
    "    x = conv2d_bn(inputs, 32, 3, 3, strides=(2, 2), padding='valid')\n",
    "    x = conv2d_bn(x, 32, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 64, 3, 3, padding=\"same\")\n",
    "    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    #x = conv2d_bn(x, 80, 1, 1, padding='valid')\n",
    "    # --\n",
    "    #x = conv2d_bn(x, 192, 3, 3, padding='valid')\n",
    "    x = conv2d_bn(x, 96, 3, 3, padding='valid')\n",
    "    x = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  def inception_block_0(x):\n",
    "    #branch1x1 = conv2d_bn(x, 64, 1, 1, padding=\"same\")\n",
    "    branch1x1 = conv2d_bn(x, 48, 1, 1, padding=\"same\")\n",
    "\n",
    "    #branch5x5 = conv2d_bn(x, 48, 1, 1, padding=\"same\")\n",
    "    branch5x5 = conv2d_bn(x, 32, 1, 1, padding=\"same\")\n",
    "    #branch5x5 = conv2d_bn(branch5x5, 64, 5, 5, padding=\"same\")\n",
    "    branch5x5 = conv2d_bn(branch5x5, 48, 5, 5, padding=\"same\")\n",
    "\n",
    "    #branch3x3dbl = conv2d_bn(x, 64, 1, 1, padding=\"same\")\n",
    "    branch3x3dbl = conv2d_bn(x, 32, 1, 1, padding=\"same\")\n",
    "    #branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, padding=\"same\")\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 48, 3, 3, padding=\"same\")\n",
    "    #branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, padding=\"same\")\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 3, padding=\"same\")\n",
    "\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    branch_pool = conv2d_bn(branch_pool, 32, 1, 1, padding=\"same\")\n",
    "\n",
    "    x = tf.keras.layers.concatenate([branch1x1, branch5x5, branch3x3dbl, branch_pool])\n",
    "\n",
    "    return x\n",
    "\n",
    "  def inception_block_1(x):\n",
    "    #branch1x1 = conv2d_bn(x, 192, 1, 1, padding=\"same\")\n",
    "    branch1x1 = conv2d_bn(x, 128, 1, 1, padding=\"same\")\n",
    "\n",
    "    #branch7x7 = conv2d_bn(x, 128, 1, 1, padding=\"same\")\n",
    "    branch7x7 = conv2d_bn(x, 96, 1, 1, padding=\"same\")\n",
    "    #branch7x7 = conv2d_bn(branch7x7, 128, 1, 7, padding=\"same\")\n",
    "    branch7x7 = conv2d_bn(branch7x7, 96, 1, 7, padding=\"same\")\n",
    "    #branch7x7 = conv2d_bn(branch7x7, 192, 7, 1, padding=\"same\")\n",
    "    branch7x7 = conv2d_bn(branch7x7, 128, 7, 1, padding=\"same\")\n",
    "\n",
    "    #branch7x7dbl = conv2d_bn(x, 128, 1, 1, padding=\"same\")\n",
    "    branch7x7dbl = conv2d_bn(x, 96, 1, 1, padding=\"same\")\n",
    "    #branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1, padding=\"same\")\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 96, 7, 1, padding=\"same\")\n",
    "    #branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 1, 7, padding=\"same\")\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 96, 1, 7, padding=\"same\")\n",
    "    #branch7x7dbl = conv2d_bn(branch7x7dbl, 128, 7, 1, padding=\"same\")\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 96, 7, 1, padding=\"same\")\n",
    "    #branch7x7dbl = conv2d_bn(branch7x7dbl, 192, 1, 7, padding=\"same\")\n",
    "    branch7x7dbl = conv2d_bn(branch7x7dbl, 96, 1, 7, padding=\"same\")\n",
    "\n",
    "    branch_pool = tf.keras.layers.AveragePooling2D((3, 3), strides=(1, 1), padding='same')(x)\n",
    "    #branch_pool = conv2d_bn(branch_pool, 192, 1, 1, padding='same')\n",
    "    branch_pool = conv2d_bn(branch_pool, 128, 1, 1, padding='same')\n",
    "\n",
    "    x = tf.keras.layers.concatenate([branch1x1, branch7x7, branch7x7dbl, branch_pool])\n",
    "\n",
    "    return x\n",
    "\n",
    "  def pooling_block(x):\n",
    "    #branch3x3 = conv2d_bn(x, 384, 3, 3, strides=(2, 2), padding='valid')\n",
    "    branch3x3 = conv2d_bn(x, 256, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    #branch3x3dbl = conv2d_bn(x, 64, 1, 1)\n",
    "    branch3x3dbl = conv2d_bn(x, 48, 1, 1)\n",
    "    #branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3)\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 3)\n",
    "    #branch3x3dbl = conv2d_bn(branch3x3dbl, 96, 3, 3, strides=(2, 2), padding='valid')\n",
    "    branch3x3dbl = conv2d_bn(branch3x3dbl, 64, 3, 3, strides=(2, 2), padding='valid')\n",
    "\n",
    "    branch_pool = tf.keras.layers.MaxPooling2D((3, 3), strides=(2, 2))(x)\n",
    "\n",
    "    x = tf.keras.layers.concatenate([branch3x3, branch3x3dbl, branch_pool])  \n",
    "\n",
    "    return x\n",
    "\n",
    "  def output_block(x, n_outputs):\n",
    "    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = tf.keras.layers.Dense(n_outputs)(x)\n",
    "\n",
    "    return x\n",
    "\n",
    "  inputs = tf.keras.Input(shape=(INPUT_SIZE[0], INPUT_SIZE[1], 3))  # (224, 224, 3)\n",
    "  x = input_block(inputs)  # (25, 25, 192)\n",
    "  for i in range(2):\n",
    "    x = inception_block_0(x)  # (25, 25, 256)\n",
    "  x = pooling_block(x)  # (12, 12, 736)\n",
    "  for i in range(2):\n",
    "    x = inception_block_1(x)  # (12, 12, 768)\n",
    "  x = pooling_block(x)  # (5, 5, 1248)\n",
    "  x = output_block(x, n_outputs)  # (20,)\n",
    "\n",
    "\n",
    "  return tf.keras.Model(inputs=inputs, outputs=x, name=\"object-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MobileNet network (~70% accuracy when transfer learning)\n",
    "def mobile_net(transfer_learning=True):\n",
    "    if transfer_learning:\n",
    "        weights = \"imagenet\"\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "    base_model = tf.keras.applications.mobilenet_v2.MobileNetV2(\n",
    "        input_shape=(INPUT_SIZE[0], INPUT_SIZE[1], 3),\n",
    "        include_top=False,\n",
    "        weights=weights,\n",
    "        pooling='avg'\n",
    "    )\n",
    "\n",
    "    if transfer_learning:\n",
    "        base_model.trainable = False\n",
    "\n",
    "    inputs = base_model.input\n",
    "    x = base_model(inputs, training=False)\n",
    "    x = tf.keras.layers.Dense(512, activation='relu')(x)\n",
    "    x = tf.keras.layers.Dense(256, activation='relu')(x)\n",
    "    outputs = tf.keras.layers.Dense(n_outputs)(x)\n",
    "\n",
    "    return tf.keras.Model(inputs=inputs, outputs=outputs, name=\"object-classification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model = simple_model()\n",
    "#model = short_inception_model()\n",
    "model = mobile_net()\n",
    "\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_finder = LRFinder()\n",
    "optimizer = tf.keras.optimizers.Adam()\n",
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  # recommended to set True, but remove activation on output layer\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "_ = model.fit(ds_train, epochs=10, callbacks=[lr_finder])\n",
    "\n",
    "lr_finder.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 15\n",
    "lr = 5e-3\n",
    "steps = np.ceil(len(ds_train) / BATCH_SIZE) * n_epochs\n",
    "lr_schedule = OneCycleScheduler(lr, steps)\n",
    "optimizer = tf.keras.optimizers.Adam(lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),  # recommended to set True, but remove activation on output layer\n",
    "    optimizer=optimizer,\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=ds_val,\n",
    "    callbacks=[lr_schedule]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_schedule.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xval in ds_val.take(1).as_numpy_iterator():\n",
    "  batch_img = xval[0]\n",
    "  batch_labels = xval[1]\n",
    "  print(xval[1].shape)\n",
    "  for i in range(10):\n",
    "    img = batch_img[i, :]\n",
    "    # ground truth\n",
    "    labels = []\n",
    "    for idx in np.where(batch_labels[i, :] > 0.5)[0]:\n",
    "      labels.append(label_map_inverse[idx])\n",
    "    ground_truth = \"-\".join(labels)\n",
    "    # predictions\n",
    "    ypred = model.predict(img[np.newaxis, ...])\n",
    "    labels = []\n",
    "    for idx in np.where(ypred.squeeze() > 0.5)[0]:\n",
    "      labels.append(label_map_inverse[idx])\n",
    "    predictions = \"-\".join(labels)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(f\"Ground truth: {ground_truth}\\nPredictions: {predictions}\")\n",
    "    \n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e9b1a836ddf9aa346930cae82b85bbd056141c3e9847381fc8cfa3e4ecc35b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('objdet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
