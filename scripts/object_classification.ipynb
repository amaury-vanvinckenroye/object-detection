{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from pathlib import Path\n",
    "import os\n",
    "import glob\n",
    "\n",
    "import json\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams[\"figure.facecolor\"] = \"w\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_data = Path(\"../data/VOC2012\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train / Val\n",
    "main_path = root_data / \"ImageSets/Main\"\n",
    "\n",
    "def get_dataset_ids(split):\n",
    "  with open(main_path / f\"{split}.txt\") as file:\n",
    "    lines = file.readlines()\n",
    "    lines = [line.rstrip() for line in lines]\n",
    "  return pd.DataFrame(\n",
    "    np.array(lines).T,\n",
    "    columns=(\"imageName\",)\n",
    "  )\n",
    "\n",
    "df_train = get_dataset_ids(\"train\")\n",
    "print(f\"len train: {len(df_train)}\")\n",
    "\n",
    "df_val = get_dataset_ids(\"val\")\n",
    "print(f\"len val: {len(df_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect labels\n",
    "labels_train = []\n",
    "labels_val = []\n",
    "\n",
    "for filename in main_path.glob(\"*.txt\"):\n",
    "  parts = filename.stem.split(\"_\")\n",
    "  # ignore train.txt and val.txt\n",
    "  if len(parts) != 2: \n",
    "    continue\n",
    "\n",
    "  label, split = parts[0], parts[1]\n",
    "  if split == \"train\":\n",
    "    labels_train.append(label)\n",
    "  elif split == \"val\":\n",
    "    labels_val.append(label)\n",
    "  else:\n",
    "    # trainval\n",
    "    continue\n",
    "\n",
    "assert sorted(labels_train) == sorted(labels_val)\n",
    "\n",
    "# build label map\n",
    "label_map = {label: i for i, label in enumerate(sorted(labels_train))}\n",
    "label_map_inverse = {i: label for label, i in label_map.items()}\n",
    "n_outputs = len(label_map)\n",
    "label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build y_train & y_val\n",
    "include_difficult = True\n",
    "\n",
    "def build_y_dict(df, split):\n",
    "    \"\"\"Builds a dictionary with the image name as keys and the one-hot representation of labels as values\n",
    "    TODO add mask for difficult cases\n",
    "    \"\"\"\n",
    "    y_dict = {}\n",
    "    # initialize all keys of the dict\n",
    "    for row in df.itertuples():\n",
    "        y_dict[row.imageName] = np.zeros(len(label_map))\n",
    "\n",
    "    # loop through every label txt file\n",
    "    for label, idx in label_map.items():\n",
    "        with open(main_path / f\"{label}_{split}.txt\") as file:\n",
    "            lines = file.readlines()\n",
    "            lines = [line.rstrip() for line in lines]\n",
    "        for line in lines:\n",
    "            parts = line.split(\" \")\n",
    "            image_name, ground_truth = parts[0], parts[-1]\n",
    "            if ground_truth == \"1\":\n",
    "                y_dict[image_name][idx] = 1\n",
    "            elif ground_truth == \"0\" and include_difficult:\n",
    "                y_dict[image_name][idx] = 1\n",
    "\n",
    "    return y_dict\n",
    "\n",
    "y_train = build_y_dict(df_train, \"train\")\n",
    "y_val = build_y_dict(df_val, \"val\")\n",
    "\n",
    "n_train, n_val = len(y_train), len(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build tf datasets\n",
    "jpeg_path = root_data / \"JPEGImages\"\n",
    "\n",
    "def buid_tf_datasets(y_dict):\n",
    "    jpeg_list = [str((jpeg_path / f\"{image_name}.jpg\").resolve()) for image_name in y_dict.keys()]\n",
    "    labels = [val for val in y_dict.values()]\n",
    "    return tf.data.Dataset.from_tensor_slices((jpeg_list, labels))\n",
    "\n",
    "ds_train = buid_tf_datasets(y_train)\n",
    "ds_val = buid_tf_datasets(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load and preprocess images\n",
    "INPUT_SIZE = (224, 224)\n",
    "\n",
    "def rescale(image):\n",
    "    return tf.math.divide(image, 255)\n",
    "\n",
    "def resize(image):\n",
    "    # tf.image.resize raises an error about images having no shape\n",
    "    #image = tf.image.resize(image, (INPUT_SIZE[0], INPUT_SIZE[1]), method=tf.image.ResizeMethod.BILINEAR)\n",
    "    #return tf.image.resize_with_pad(image, INPUT_SIZE[0], INPUT_SIZE[1], method=tf.image.ResizeMethod.BILINEAR, antialias=True)\n",
    "    return tf.image.resize(image, (INPUT_SIZE[0], INPUT_SIZE[1]), method=tf.image.ResizeMethod.BILINEAR, antialias=True)\n",
    "\n",
    "def clip_values(image):\n",
    "    return tf.clip_by_value(image, 0, 1)\n",
    "\n",
    "def preprocess_image(image):\n",
    "    image = clip_values(resize(rescale(image)))\n",
    "    return image\n",
    "\n",
    "def load_and_preprocess_image(image_path, labels):\n",
    "    img_content = tf.io.read_file(image_path)\n",
    "    image = tf.io.decode_jpeg(img_content)\n",
    "    return (preprocess_image(image), labels)\n",
    "\n",
    "ds_train = (\n",
    "    ds_train\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    ds_val\n",
    "    .map(load_and_preprocess_image, num_parallel_calls=tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for x in ds_train.as_numpy_iterator():\n",
    "  fig, ax = plt.subplots()\n",
    "  ax.imshow(x[0])\n",
    "  break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "\n",
    "ds_train = (\n",
    "    ds_train\n",
    "    .cache()\n",
    "    .shuffle(n_train)\n",
    "    .batch(BATCH_SIZE)\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")\n",
    "\n",
    "ds_val = (\n",
    "    ds_val\n",
    "    .batch(BATCH_SIZE)\n",
    "    .cache()  # caching is done after batching because batches can be the same between epochs\n",
    "    .prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tf.keras.Input(shape=(INPUT_SIZE[0], INPUT_SIZE[1], 3))\n",
    "x = tf.keras.layers.Conv2D(16, 3, padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Conv2D(32, 5, padding=\"same\", activation=\"relu\")(x)\n",
    "x = tf.keras.layers.MaxPooling2D(3, 1)(x)\n",
    "x = tf.keras.layers.Conv2D(64, 9, padding=\"same\", activation=\"relu\")(inputs)\n",
    "x = tf.keras.layers.Conv2D(128, 17, padding=\"same\", activation=\"relu\")(x)\n",
    "x = tf.keras.layers.GlobalMaxPooling2D()(x)\n",
    "outputs = tf.keras.layers.Dense(n_outputs, activation=\"sigmoid\")(x)\n",
    "\n",
    "model = tf.keras.Model(inputs=inputs, outputs=outputs, name=\"object-classification\")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=\"binary_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    ds_train,\n",
    "    epochs=5,\n",
    "    validation_data=ds_val\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for xval in ds_val.take(1).as_numpy_iterator():\n",
    "  batch_img = xval[0]\n",
    "  batch_labels = xval[1]\n",
    "  print(xval[1].shape)\n",
    "  for i in range(10):\n",
    "    img = batch_img[i, :]\n",
    "    # ground truth\n",
    "    labels = []\n",
    "    for idx in np.where(batch_labels[i, :] > 0.5)[0]:\n",
    "      labels.append(label_map_inverse[idx])\n",
    "    ground_truth = \"-\".join(labels)\n",
    "    # predictions\n",
    "    ypred = model.predict(img[np.newaxis, ...])\n",
    "    labels = []\n",
    "    for idx in np.where(ypred.squeeze() > 0.5)[0]:\n",
    "      labels.append(label_map_inverse[idx])\n",
    "    predictions = \"-\".join(labels)\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_title(f\"Ground truth: {ground_truth}\\nPredictions: {predictions}\")\n",
    "    \n",
    "    ax.imshow(img)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4e9b1a836ddf9aa346930cae82b85bbd056141c3e9847381fc8cfa3e4ecc35b8"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('objdet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
